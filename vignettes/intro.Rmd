---
title: "Introduction to StatComp22030"
author: "22030"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to StatComp22030}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup}
library(StatComp22030)
```


## Overview

__StatComp22030__ is a R package of the final project of 22030. It conducts a model averaging method for quantile regression, using J-fold cross-validation. It also compare the performance of R and C++ (implemented through the R package _Rcpp_) for the 'Statistical Computing' course, using _gibbsR_ for R and _gibbsC_ for C++.

## Model averaging for quantile regression 

We propose a model averaging method for quantile regression and use J-fold cross-validation to determine the weights of candidate models.

Let $\left\{\left(y_{i},  \mathbf{x}_{i}\right)\right\}_{i=1}^{n}$ be a group of independent and identically distributed (IID) random samples, where $y_i$ is a scalar dependent variable and $\mathbf{x}_{i}=\left(x_{i 1},  x_{i 2},  \ldots, x_{ip}\right)$ is a $p$ dimensional explanatory variable. Without loss of generality, assume that the first column of $X$ is 1.
We want to predict the $\tau$th quantile $\mu_{i}$ of $y_i$ using model averaging.

Consider $M=p$ approximate models containing different covariates, where the set of candidate models are nested. Write the $m$th candidate model as
$$
y_{i}=\boldsymbol{\theta}_{(m)}^{\prime} \mathbf{x}_{i(m)}+\varepsilon_{i(m)}=\sum_{j=1}^{m} \theta_{j(m)} x_{i j(m)}+\varepsilon_{i(m)}, 
$$
where $\boldsymbol{\theta}_{(m)} =\left(\theta_{1(m)},  \ldots,  \theta_{m(m)}\right)^{\prime},  \mathbf{x}_{i(m)}=\left(x_{i 1(m)},  \ldots,  x_{i m(m)}\right)^{\prime}$.

For the $m$th candidate model, the estimator of $\boldsymbol{\theta}_{(m)}$ is given by
$$
\begin{aligned}
\hat{\boldsymbol{\theta}}_{(m)} 
&=\arg \min _{\boldsymbol{\theta}_{(m)}} \sum_{i=1}^{n} \rho_{\tau}\left(y_{i}-\boldsymbol{\theta}_{(m)}^{\prime} \mathbf{x}_{i(m)}\right),
\end{aligned}
$$

where $\rho_{\tau}(\lambda)=[\tau-\mathbf{1}\{\lambda \leq 0\}]\lambda$ is the check loss.

Let $\mathbf{w} = \left(w_{1},  \ldots,  w_{M}\right)^{\prime}$ be a weight vector in $\mathcal{W} =\left\{\mathbf{w} \in[0, 1]^{M}: \sum_{m=1}^{M} w_{m}=1\right\}$. 
For $i=1,  \ldots,  n$, the model averaging estimator of $\mu_{i}$ is given by
$$
\hat{\mu}_{i}(\mathbf{w})=\sum_{m=1}^{M} w_{m} \mathbf{x}_{i(m)}^{\prime} \hat{\boldsymbol{\theta}}_{(m)}.
$$

Now we use J-fold cross-validation to choose the weights. 

We randomly divide the dataset into $J$ groups ($J \geq 2$ is a positive finite integer), each with $Q=n/J$ observations.
For $m = 1, \ldots , M$, let $\tilde{\boldsymbol{\theta}}_{(m)}^{[-j]}$ denotes
the estimator of  $\boldsymbol{\theta}_{(m)}$ in the $m$th model after leaving out the $j$th group of observations. For $i=(j-1)Q+1,\ldots, jQ$ in the $j$th grounp, we form the estimator of $\mu_i$ as
$\tilde{\mu}_{i}^{[-j]}(\mathbf{w}) = \sum_{m=1}^{M} w_{m} \mathbf{x}_{i(m)}^{ \prime} \tilde{\boldsymbol{\theta}}_{(m)}^{[-j]}.$ 

Our JCV criterion is formulated as
\begin{equation}\label{eq:weight_criterion}
\operatorname{CV}_{n}^J(\mathbf{w})=\frac{1}{n} 
\sum_{j=1}^{J} \sum_{q=1}^{Q}
\rho_{\tau}\left(y_{(j-1)Q+q}-\tilde{\mu}_{(j-1)Q+q}^{[-j]}
(\mathbf{w})\right).
\end{equation}
The JCV weight vector $\hat{\mathbf{w}}=\left(\hat{w}_{1},  \ldots,  \hat{w}_{M}\right)'$ is obtained by choosing $\mathbf{w} \in \mathcal{W}$ to minimize the above criterion function, i.e.,
\begin{equation}
\label{eq:argmin}
\hat{\mathbf{w}}=\arg \min _{\mathbf{w} \in \mathcal{W}} \operatorname{C V}^J_{n}(\mathbf{w}).
\end{equation}

We can convert the above constrained optimization problem to the following linear programming problem:
$$
\begin{aligned}
&\min _{\mathbf{w},  \mathbf{u},  \mathbf{v}}\left\{
\tau \mathbf{1}_{n}^{\prime} \mathbf{u}+(1-\tau) \mathbf{1}_{n}^{\prime} \mathbf{v}\right\} \\
\text { s.t. } & \sum_{m=1}^{M} w_{m} \mathbf{x}_{((j-1)Q+q)(m)}^{ \prime} \tilde{\boldsymbol{\theta}}_{(m)}^{[-j]}
+u_{(j-1)Q+q}-v_{(j-1)Q+q}=y_{(j-1)Q+q},  \\
&u_{(j-1)Q+q}\geq 0,  v_{(j-1)Q+q}\geq 0 ,  j=1,  \ldots,  J,  q=1,  \ldots,  Q,   \\
&\sum_{m=1}^{M} w_{m}=1, 
0 \leq w_{m} \leq 1,  m=1,  \ldots,  M, 
\end{aligned}
$$
where $\mathbf{u} =\left(u_{1},  u_{2},  \ldots,  u_{n}\right)^{\prime}$ and  $\mathbf{v} =\left(v_{1},  v_{2},  \ldots,  v_{n}\right)^{\prime}$ are the positive and negative slack variables and $\mathbf{1}_{n}$ is $n \times 1$ vector of ones.

We first define the indicator function \code{Indic} $\mathbf{1}\{e \leq 0\}$.
```{r,eval=FALSE}
function(e){
  g<-rep(0,length(e))
  g[which(e<=0)]=1
  g
}
```

The following function \code{qrma} conducts model averaging by J-fold cross-validation.
```{r,eval=FALSE}
library(quantreg)
library(lpSolve)
function(X, y, J=5, tau=0.5){
  data<-cbind(y,X)
  n<-length(y)
  Q<-floor(n/J)
  M<-dim(X)[2]
  # the estimator of theta in the mth model
  theta.hat<-matrix(0,M,M)
  for (m in 1:M) {
    fit<-rq(data=data.frame(X[,1:m]), y~0+.,tau=tau)
    theta.hat[1:m,m]<-fit$coefficients
  }
  # divide the data to J groups
  index <- rep(1:J,Q) 
  index <- sample(index,n)
  mu<-matrix(0, n, M) 
  y.CV<-rep(0, n) 
  # prepare the data for CV
  for (j in 1:J) {
    data.train<-data[index!=j,]
    data.test<-data[index==j,]
    for (m in 1:M) {
      suppressWarnings(rq.m<-rq(data.train[,1]~0+.,tau=tau,
                                data=data.frame(data.train[,-1][,1:m])))
      mu[((j-1)*Q+1):(j*Q),m]<-as.matrix(data.test[,-1][,1:m])%*%
        as.matrix(rq.m$coefficients)
    }
    y.CV[((j-1)*Q+1):(j*Q)]<-data.test[,1]
  } 
  # solve lp to get the weights
  obj1<-rep(tau,len=n);obj2<-rep(1-tau,len=n);obj3<-rep(0,len=M)
  f.obj<-c(obj1,obj2,obj3)
  con1<-diag(2*n+M)
  con21<-matrix(0,nrow = M,ncol = 2*n);
  con22<-diag(M);
  con2<-cbind(con21,con22) 
  con3<-c(rep(0,len=2*n),rep(1,len=M))
  con4<-cbind(diag(n),-diag(n),mu)
  f.con<-rbind(con1,con2,con3,con4) 
  f.dir<-c(rep(">=",len=2*n+M),rep("<=",len=M),rep("=",len=n+1) ) 
  f.rhs<-c(rep(0,len=2*n+M),rep(1,len=M+1), y.CV) 
  lp.result<-lp("min", f.obj, f.con, f.dir, f.rhs)
  w.JCVMA<-lp.result$solution[(2*n+1):(2*n+M)]
  muhat<-as.matrix(X) %*% theta.hat
  y.hat<-muhat %*% w.JCVMA
  PE<-(tau-Indic(y-y.hat))%*%(y-y.hat)/n
  return(list(w.JCVMA=w.JCVMA, theta.hat=theta.hat, y.hat=y.hat, PE=PE))
}
```

The following function \code{predict_qr} predicts $\mu$ given covariates $x$.
```{r,eval=FALSE}
function(x, qrma){
  n<-dim(x)[1]
  M<-dim(x)[2]
  muhat<-as.matrix(x) %*% qrma$theta.hat
  y.hat<-muhat %*% qrma$w.JCVMA
  return(y.hat)
}
```

Example:
```{r}
data(express)
attach(express)
y<-express$y[1:100]
y.s<-express$y[101:150]
X<-express[1:100,-1]
X.s<-express[101:150,-1]
tau<-0.5
qrma.fit<-qrma(X, y, J=5, tau = tau)
w<-qrma.fit$w.JCVMA # weight
PE<-qrma.fit$PE # in-sample FPE
y.hat<-predict_qr(X.s,qrma.fit) # estimation

tau<-0.05
qrma.fit<-qrma(X, y, J=5, tau = tau)
qrma.fit<-qrma(X, y, J=5, tau = tau)
w<-qrma.fit$w.JCVMA # weight
PE<-qrma.fit$PE # in-sample FPE
y.hat<-predict_qr(X.s,qrma.fit) # estimation

```


## Benchmarking _gibbsR_ and _gibbsC_

The source R code for _gibbsR_ is as follows:
```{r,eval=FALSE}
function(N) {
  mat <- matrix(nrow = N, ncol = 2)
  rho <- 0.9 # correlation
  mu1<-mu2<-0
  sigma1<-sigma2<-1
  s1 <- sqrt(1-rho^2)*sigma1
  s2 <- sqrt(1-rho^2)*sigma2
  x <- y <- 0
  for (i in 1:N) {
    x <- rnorm(1, mu1 + rho * (y - mu2) * sigma1/sigma2, s1)
    y <- rnorm(1, mu2 + rho * (x - mu1) * sigma2/sigma1, s2)
    mat[i, ] <- c(x, y)
  }
  mat
}
```

The source R code for _gibbsC_ is as follows:
```{r,eval=FALSE}
NumericMatrix gibbsC(int N) {
  NumericMatrix mat(N, 2);
  double  rho=0.9, mu1=0, mu2=0, sigma1=1, sigma2=1, s1=0, s2=0;
  s1 = sqrt(1-rho*rho)*sigma1;
  s2 = sqrt(1-rho*rho)*sigma2;
  double x = 0, y = 0;
  for(int i = 0; i < N; i++) {
    x = rnorm(1, mu1 + rho * (y - mu2) * sigma1/sigma2, s1)[0];
    y = rnorm(1, mu2 + rho * (x - mu1) * sigma2/sigma1, s2)[0];
    mat(i, 0) = x;
    mat(i, 1) = y;
  }
  return(mat);
}
```





